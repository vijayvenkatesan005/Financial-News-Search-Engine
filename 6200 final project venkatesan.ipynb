{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from datetime import datetime\n",
    "from flask import Flask, render_template, request\n",
    "import csv\n",
    "from textblob import TextBlob\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "es = Elasticsearch([{'host': 'localhost', 'port':9200, 'scheme': 'http'}], http_auth=(\"vijay\", \"password\"))\n",
    "es.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tech_companies_financial_data_documents = list()\n",
    "\n",
    "with open(\"data.csv\", \"r\", encoding='utf-8') as file:\n",
    "\n",
    "    reader = csv.reader(file)\n",
    "    \n",
    "    headers = next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "\n",
    "        data = dict()\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for h in headers:\n",
    "\n",
    "            data[h] = row[i]  \n",
    "            i += 1\n",
    "\n",
    "        \n",
    "        tech_companies_financial_data_documents.append(data)\n",
    "\n",
    "\n",
    "print(tech_companies_financial_data_documents[:10])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbc_documents = list()\n",
    "guardian_documents = list()\n",
    "reuters_documents = list()\n",
    "\n",
    "with open(\"cnbc_headlines.csv\", \"r\", encoding='utf-8') as file:\n",
    "\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    headers = next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "\n",
    "        data = dict()\n",
    "\n",
    "        data['News Organization'] = 'CNBC'\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for h in headers:\n",
    "\n",
    "            data[h] = row[i]\n",
    "            i += 1\n",
    "        \n",
    "        cnbc_documents.append(data)\n",
    "\n",
    "\n",
    "with open(\"guardian_headlines.csv\", \"r\", encoding='utf-8') as file:\n",
    "\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    headers = next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "\n",
    "        data = dict()\n",
    "\n",
    "        data['News Organization'] = 'The Guardian'\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for h in headers:\n",
    "\n",
    "            data[h] = row[i]\n",
    "            i += 1\n",
    "        \n",
    "        guardian_documents.append(data)\n",
    "\n",
    "\n",
    "with open(\"reuters_headlines.csv\", \"r\", encoding='utf-8') as file:\n",
    "\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    headers = next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "\n",
    "        data = dict()\n",
    "\n",
    "        data['News Organization'] = 'Reuters'\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for h in headers:\n",
    "\n",
    "            data[h] = row[i]\n",
    "            i += 1\n",
    "        \n",
    "        reuters_documents.append(data)\n",
    "\n",
    "\n",
    "print(cnbc_documents[:10])\n",
    "print()\n",
    "\n",
    "print(guardian_documents[:10])\n",
    "print()\n",
    "\n",
    "print(reuters_documents[:10])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_documents(index, id, document):\n",
    "    \n",
    "    resp = es.index(index=index, id=id, document=document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(tech_companies_financial_data_documents)):\n",
    "\n",
    "    es.index(index = \"tech_company_index\", id = i + 1, document = tech_companies_financial_data_documents[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cnbc_documents)):\n",
    "    \n",
    "    es.index(index = \"cnbc_index\", id = i + 1, document = cnbc_documents[i])\n",
    "\n",
    "for i in range(len(guardian_documents)):\n",
    "    \n",
    "    es.index(index = \"guardian_index\", id = i + 1, document = guardian_documents[i])\n",
    "\n",
    "for i in range(len(reuters_documents)):\n",
    "    \n",
    "    es.index(index = \"reuters_index\", id = i + 1, document = reuters_documents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = es.get(index=\"tech_company_index\", id=1)\n",
    "print(resp['_source'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = es.get(index=\"cnbc_index\", id=1)\n",
    "print(resp['_source'])\n",
    "print()\n",
    "\n",
    "resp = es.get(index=\"guardian_index\", id=1)\n",
    "print(resp['_source'])\n",
    "print()\n",
    "\n",
    "resp = es.get(index=\"reuters_index\", id=1)\n",
    "print(resp['_source'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_search_history(history):\n",
    "\n",
    "    if len(history) < 2:\n",
    "\n",
    "        return None\n",
    "    \n",
    "    most_frequent_term_dict = {}\n",
    "\n",
    "    for query_term in history[:-1]:\n",
    "\n",
    "        if query_term in most_frequent_term_dict:\n",
    "\n",
    "            most_frequent_term_dict[query_term] += 1\n",
    "        \n",
    "        else:\n",
    "\n",
    "            most_frequent_term_dict[query_term] = 1\n",
    "    \n",
    "    result = max(most_frequent_term_dict, key=most_frequent_term_dict.get)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_query(query, datasets_to_search, index_names):\n",
    "\n",
    "    global search_history\n",
    "\n",
    "    most_frequent_term = analyze_search_history(search_history)\n",
    "\n",
    "    if most_frequent_term:\n",
    "\n",
    "        query += \" \" + most_frequent_term\n",
    "\n",
    "    print(query)\n",
    "    \n",
    "    body = {\n",
    "        \"size\": 20,\n",
    "        \"query\": {\n",
    "            \"bool\": {\n",
    "                \"should\": [\n",
    "                    {\"match\": {\"Headlines\": query}},\n",
    "                    {\"match\": {\"Description\": query}}\n",
    "                ],\n",
    "                \"minimum_should_match\": 1\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(datasets_to_search)):\n",
    "\n",
    "        resp = es.search(index=index_names[i], body=body)\n",
    "\n",
    "        for hit in resp['hits']['hits']:\n",
    "            \n",
    "            news_organization = hit[\"_source\"].get('News Organization')\n",
    "            headline = hit[\"_source\"].get('Headlines')\n",
    "            time = hit[\"_source\"].get('Time')\n",
    "            description = hit[\"_source\"].get('Description')\n",
    "\n",
    "            if description:\n",
    "\n",
    "                sentiment = TextBlob(description).sentiment.polarity\n",
    "                sentiment_label = 'positive' if sentiment > 0 else 'negative' if sentiment < 0 else 'neutral'\n",
    "            \n",
    "            else:\n",
    "\n",
    "                sentiment_label = 'Not Applicable'\n",
    "\n",
    "\n",
    "\n",
    "            formatted_result = f\"'News Organization': {news_organization}\\nHeadline: {headline}\\nTime: {time}\\nDescription: {description}\\nSentiment: {sentiment_label}\\n\\n\"\n",
    "            \n",
    "            formatted_result = formatted_result.replace('\\n', '<br>')\n",
    "\n",
    "            results.append(formatted_result)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "financial_synonyms = {\n",
    "    \"stock\": [\"shares\", \"equity\", \"stock market\", \"securities\"],\n",
    "    \"bond\": [\"debt securities\", \"fixed income\", \"notes\", \"debt\"],\n",
    "    \"market\": [\"marketplace\", \"trading place\", \"exchange\"],\n",
    "    \"investment\": [\"investing\", \"capital placement\", \"asset allocation\"],\n",
    "    \"economy\": [\"economic system\", \"financial system\", \"market system\"],\n",
    "    \"currency\": [\"money\", \"cash\", \"legal tender\", \"fiat\"],\n",
    "    \"bank\": [\"banking institution\", \"lender\", \"financial institution\"],\n",
    "    \"trade\": [\"trading\", \"buying and selling\", \"commerce\"],\n",
    "    \"inflation\": [\"price rise\", \"economic inflation\", \"monetary inflation\"],\n",
    "    \"mortgage\": [\"home loan\", \"property loan\", \"loan for real estate\"],\n",
    "    \"recession\": [\"economic downturn\", \"depression\", \"slowdown\"],\n",
    "    \"portfolio\": [\"investment mix\", \"asset mix\", \"asset collection\"],\n",
    "    \"dividend\": [\"profit sharing\", \"payout\", \"share of profits\"],\n",
    "    \"risk\": [\"uncertainty\", \"exposure\", \"financial risk\"],\n",
    "    \"credit\": [\"borrowing\", \"lending\", \"credit line\"],\n",
    "    \"tax\": [\"taxation\", \"levy\", \"duty\"],\n",
    "    \"profit\": [\"earnings\", \"gain\", \"financial gain\"],\n",
    "    \"loss\": [\"deficit\", \"financial loss\", \"shortfall\"],\n",
    "    \"interest\": [\"interest rate\", \"borrowing cost\", \"lending rate\"],\n",
    "    \"commodity\": [\"raw material\", \"basic good\", \"tradeable item\"],\n",
    "    \"acquisition\": [\"takeover\", \"purchase\", \"buyout\"],\n",
    "    \"bankruptcy\": [\"insolvency\", \"financial failure\", \"liquidation\"]\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def expand_query(query):\n",
    "\n",
    "    expanded_terms = list()\n",
    "\n",
    "    for word in query.split():\n",
    "\n",
    "        expanded_terms.append(word)\n",
    "\n",
    "        if word in financial_synonyms:\n",
    "\n",
    "            expanded_terms.extend(financial_synonyms[word])\n",
    "    \n",
    "    return \" OR \".join(expanded_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_tech_companies(query):\n",
    "\n",
    "    body = {\n",
    "        \"size\": 20,\n",
    "        \"query\": {\n",
    "            \"match\": {\"Company\": query}\n",
    "        }   \n",
    "    }\n",
    "\n",
    "    results = []\n",
    "    \n",
    "    resp = es.search(index=\"tech_company_index\", body=body)\n",
    "\n",
    "    for hit in resp['hits']['hits']:\n",
    "\n",
    "        if len(results) < 20:\n",
    "        \n",
    "            company = hit[\"_source\"].get('Company')\n",
    "            date = hit[\"_source\"].get('Date')\n",
    "            last_trade = hit[\"_source\"].get('Close/Last')\n",
    "            volume = hit[\"_source\"].get('Volume')\n",
    "            \n",
    "            open = hit[\"_source\"].get('Open')\n",
    "            high = hit[\"_source\"].get('High')\n",
    "            low = hit[\"_source\"].get('Low')\n",
    "\n",
    "            formatted_result = f\"Company: {company}\\nDate: {date}\\nClose/Last: {last_trade}\\nVolume: {volume}\\nOpen: {open}\\nHigh: {high}\\nLow: {low}\\n\\n\"\n",
    "            \n",
    "            formatted_result = formatted_result.replace('\\n', '<br>')\n",
    "\n",
    "            results.append(formatted_result)\n",
    "        \n",
    "        else:\n",
    "\n",
    "            break\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def homepage():\n",
    "\n",
    "    global search_history\n",
    "\n",
    "    results = []\n",
    "\n",
    "    search_executed = False\n",
    "\n",
    "    show_search_history = False\n",
    "\n",
    "    clear_search_history = False\n",
    "\n",
    "    show_news_form = False\n",
    "\n",
    "    checked_state = {'cnbc' : False, 'the_guardian' : False, 'reuters' : False}\n",
    "\n",
    "    show_historical_data_form = False\n",
    "\n",
    "    if request.method == 'POST':\n",
    "\n",
    "        if 'news' in request.form:\n",
    "\n",
    "            show_news_form = True\n",
    "        \n",
    "        elif 'news_search' in request.form:\n",
    "\n",
    "            query = request.form.get('search_query')\n",
    "            selected_sentiment = request.form.get('sentiment')\n",
    "\n",
    "            if query:\n",
    "                \n",
    "                search_history.append(query) \n",
    "            \n",
    "            search_executed = True\n",
    "\n",
    "            datasets_to_search = list()\n",
    "            index_names = list()\n",
    "\n",
    "            if request.form.get('cnbc'):\n",
    "\n",
    "                datasets_to_search.append(cnbc_documents)\n",
    "                index_names.append(\"cnbc_index\")\n",
    "                checked_state['cnbc'] = True\n",
    "                \n",
    "            \n",
    "            if request.form.get('the_guardian'):\n",
    "\n",
    "                datasets_to_search.append(guardian_documents)\n",
    "                index_names.append(\"guardian_index\")\n",
    "                checked_state['the_guardian'] = True\n",
    "            \n",
    "            if request.form.get('reuters'):\n",
    "\n",
    "                datasets_to_search.append(reuters_documents)\n",
    "                index_names.append(\"reuters_index\")\n",
    "                checked_state['reuters'] = True\n",
    "\n",
    "\n",
    "            results = search(query, datasets_to_search, index_names)\n",
    "\n",
    "\n",
    "            if selected_sentiment != 'all':\n",
    "\n",
    "                filtered_results = []\n",
    "\n",
    "                for result in results:\n",
    "\n",
    "                    if selected_sentiment in result:\n",
    "\n",
    "                        filtered_results.append(result)\n",
    "                \n",
    "                results = filtered_results\n",
    "        \n",
    "\n",
    "        if 'historical_data' in request.form:\n",
    "\n",
    "            show_historical_data_form = True\n",
    "        \n",
    "        elif \"historical_data_search\" in request.form:\n",
    "\n",
    "            query = request.form.get(\"historical_search_query\")\n",
    "\n",
    "            if query:\n",
    "                \n",
    "                search_history.append(query) \n",
    "\n",
    "            search_executed = True\n",
    "\n",
    "            results = search_tech_companies(query)\n",
    "        \n",
    "\n",
    "        if 'show_history' in request.form:\n",
    "\n",
    "            show_search_history = True\n",
    "        \n",
    "\n",
    "        if 'clear_history' in request.form:\n",
    "\n",
    "            clear_search_history = True\n",
    "            search_history.clear()\n",
    "\n",
    "    return render_template('test.html', results=results, checked_state=checked_state, search_executed=search_executed, show_news_form=show_news_form, \n",
    "                           show_historical_data_form=show_historical_data_form, search_history=search_history, show_search_history=show_search_history, \n",
    "                           clear_search_history=clear_search_history)\n",
    "\n",
    "def search(query, datasets_to_search, index_names):\n",
    "    \n",
    "    return search_query(query, datasets_to_search, index_names)\n",
    "\n",
    "\n",
    "app.run(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
