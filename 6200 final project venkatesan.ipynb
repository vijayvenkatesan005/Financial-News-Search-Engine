{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from datetime import datetime\n",
    "from flask import Flask, render_template, request\n",
    "import csv\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "es = Elasticsearch([{'host': 'localhost', 'port':9200, 'scheme': 'http'}], http_auth=(\"vijay\", \"password\"))\n",
    "es.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnbc_documents = list()\n",
    "guardian_documents = list()\n",
    "reuters_documents = list()\n",
    "\n",
    "with open(\"cnbc_headlines.csv\", \"r\", encoding='utf-8') as file:\n",
    "\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    headers = next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "\n",
    "        data = dict()\n",
    "\n",
    "        data['News Organization'] = 'CNBC'\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for h in headers:\n",
    "\n",
    "            data[h] = row[i]\n",
    "            i += 1\n",
    "        \n",
    "        cnbc_documents.append(data)\n",
    "\n",
    "\n",
    "with open(\"guardian_headlines.csv\", \"r\", encoding='utf-8') as file:\n",
    "\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    headers = next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "\n",
    "        data = dict()\n",
    "\n",
    "        data['News Organization'] = 'The Guardian'\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for h in headers:\n",
    "\n",
    "            data[h] = row[i]\n",
    "            i += 1\n",
    "        \n",
    "        guardian_documents.append(data)\n",
    "\n",
    "\n",
    "with open(\"reuters_headlines.csv\", \"r\", encoding='utf-8') as file:\n",
    "\n",
    "    reader = csv.reader(file)\n",
    "\n",
    "    headers = next(reader)\n",
    "\n",
    "    for row in reader:\n",
    "\n",
    "        data = dict()\n",
    "\n",
    "        data['News Organization'] = 'Reuters'\n",
    "\n",
    "        i = 0\n",
    "\n",
    "        for h in headers:\n",
    "\n",
    "            data[h] = row[i]\n",
    "            i += 1\n",
    "        \n",
    "        reuters_documents.append(data)\n",
    "\n",
    "\n",
    "print(cnbc_documents[:10])\n",
    "print()\n",
    "\n",
    "print(guardian_documents[:10])\n",
    "print()\n",
    "\n",
    "print(reuters_documents[:10])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_documents(index, id, document):\n",
    "    \n",
    "    resp = es.index(index=index, id=id, document=document)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cnbc_documents)):\n",
    "    \n",
    "    es.index(index = \"cnbc_index\", id = i + 1, document = cnbc_documents[i])\n",
    "\n",
    "for i in range(len(guardian_documents)):\n",
    "    \n",
    "    es.index(index = \"guardian_index\", id = i + 1, document = guardian_documents[i])\n",
    "\n",
    "for i in range(len(reuters_documents)):\n",
    "    \n",
    "    es.index(index = \"reuters_index\", id = i + 1, document = reuters_documents[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = es.get(index=\"cnbc_index\", id=1)\n",
    "print(resp['_source'])\n",
    "print()\n",
    "\n",
    "resp = es.get(index=\"guardian_index\", id=1)\n",
    "print(resp['_source'])\n",
    "print()\n",
    "\n",
    "resp = es.get(index=\"reuters_index\", id=1)\n",
    "print(resp['_source'])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def search_query(query, datasets_to_search, index_names):\n",
    "    \n",
    "    body = {\n",
    "        \"size\": 20,\n",
    "        \"query\": {\n",
    "            \"dis_max\": {\n",
    "                \"queries\": [\n",
    "                    {\"match\": {\"Headlines\": query}},\n",
    "                    {\"match\": {\"Description\": query}}\n",
    "                ],\n",
    "                \"tie_breaker\": 0.3\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for i in range(len(datasets_to_search)):\n",
    "\n",
    "        resp = es.search(index=index_names[i], body=body)\n",
    "\n",
    "        for hit in resp['hits']['hits']:\n",
    "            \n",
    "            news_organization = hit[\"_source\"].get('News Organization')\n",
    "            headline = hit[\"_source\"].get('Headlines')\n",
    "            time = hit[\"_source\"].get('Time')\n",
    "            description = hit[\"_source\"].get('Description')\n",
    "\n",
    "            formatted_result = f\"'News Organization': {news_organization}\\nHeadline: {headline}\\nTime: {time}\\nDescription: {description}\\n\\n\"\n",
    "            \n",
    "            formatted_result = formatted_result.replace('\\n', '<br>')\n",
    "\n",
    "            results.append(formatted_result)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/', methods=['GET', 'POST'])\n",
    "def homepage():\n",
    "\n",
    "    results = []\n",
    "\n",
    "    if request.method == 'POST':\n",
    "\n",
    "        query = request.form.get('search_query')\n",
    "\n",
    "        datasets_to_search = list()\n",
    "        index_names = list()\n",
    "\n",
    "        if request.form.get('cnbc'):\n",
    "\n",
    "            datasets_to_search.append(cnbc_documents)\n",
    "            index_names.append(\"cnbc_index\")\n",
    "        \n",
    "        if request.form.get('the guardian'):\n",
    "\n",
    "            datasets_to_search.append(guardian_documents)\n",
    "            index_names.append(\"guardian_index\")\n",
    "        \n",
    "        if request.form.get('reuters'):\n",
    "\n",
    "            datasets_to_search.append(reuters_documents)\n",
    "            index_names.append(\"reuters_index\")\n",
    "\n",
    "        results = search(query, datasets_to_search, index_names)\n",
    "    \n",
    "    return render_template('test.html', results=results)\n",
    "\n",
    "def search(query, datasets_to_search, index_names):\n",
    "\n",
    "    return search_query(query, datasets_to_search, index_names)\n",
    "\n",
    "\n",
    "app.run(debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
